{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%run utils.ipynb\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dos_df,fuzzy_df,attack_free_df=load_data(\"out_paths\",lib=\"pd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_dos_df=dos_df[dos_df[\"updated_flag\"]=='T']\n",
    "only_fuzzy_df=fuzzy_df[fuzzy_df[\"updated_flag\"]=='T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_free_inside_dos_df=dos_df[dos_df[\"updated_flag\"]=='R']\n",
    "attack_free_inside_fuzzy_df=fuzzy_df[fuzzy_df[\"updated_flag\"]=='R']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_column_in_dataframe(df, column_name):\n",
    "    \"\"\"\n",
    "    Checks column exist or not in given df.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df :pl.DataFrame\n",
    "        Input DataFrame.\n",
    "    column_name : str\n",
    "        Column name that will be checked.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "       If the specified column does not exist in the DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    if column_name not in df.columns:\n",
    "        raise ValueError(f\"Column '{column_name}' not found in DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Noisy Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the attack-free dataset inside the fuzzy dataset, the value 6 in the dlc column appears only three times out of 3 million records. Since it is noisy, it needs to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>can_id</th>\n",
       "      <th>dlc</th>\n",
       "      <th>byte_0</th>\n",
       "      <th>byte_1</th>\n",
       "      <th>byte_2</th>\n",
       "      <th>byte_3</th>\n",
       "      <th>byte_4</th>\n",
       "      <th>byte_5</th>\n",
       "      <th>byte_6</th>\n",
       "      <th>byte_7</th>\n",
       "      <th>updated_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1546675</th>\n",
       "      <td>1.478197e+09</td>\n",
       "      <td>0105</td>\n",
       "      <td>6</td>\n",
       "      <td>eb</td>\n",
       "      <td>01</td>\n",
       "      <td>b7</td>\n",
       "      <td>00</td>\n",
       "      <td>98</td>\n",
       "      <td>02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713142</th>\n",
       "      <td>1.478197e+09</td>\n",
       "      <td>0105</td>\n",
       "      <td>6</td>\n",
       "      <td>ec</td>\n",
       "      <td>01</td>\n",
       "      <td>b8</td>\n",
       "      <td>00</td>\n",
       "      <td>be</td>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713159</th>\n",
       "      <td>1.478197e+09</td>\n",
       "      <td>0105</td>\n",
       "      <td>6</td>\n",
       "      <td>eb</td>\n",
       "      <td>01</td>\n",
       "      <td>b7</td>\n",
       "      <td>00</td>\n",
       "      <td>98</td>\n",
       "      <td>02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp can_id  dlc byte_0 byte_1 byte_2 byte_3 byte_4 byte_5  \\\n",
       "1546675  1.478197e+09   0105    6     eb     01     b7     00     98     02   \n",
       "1713142  1.478197e+09   0105    6     ec     01     b8     00     be     01   \n",
       "1713159  1.478197e+09   0105    6     eb     01     b7     00     98     02   \n",
       "\n",
       "        byte_6 byte_7 updated_flag  \n",
       "1546675    NaN    NaN            R  \n",
       "1713142    NaN    NaN            R  \n",
       "1713159    NaN    NaN            R  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attack_free_inside_fuzzy_df[attack_free_inside_fuzzy_df[\"dlc\"]==6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_free_inside_fuzzy_df=attack_free_inside_fuzzy_df[attack_free_inside_fuzzy_df[\"dlc\"]!=6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_random_sampling(df, sample_size):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Perform random sampling on a given DataFrame.\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The input dataframe from which to sample data.\n",
    "    sample_size : int\n",
    "        The number of samples to extract\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A randomly sampled DataFrame with 'sample_size' rows\n",
    "    \"\"\"\n",
    "    return df.sample(n=sample_size,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_proportionate_stratified_sampling(df,column_name, sample_fraction):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Perform proportionate stratified sampling on a given DataFrame.\n",
    "\n",
    "    This function samples a specified fraction of each unique category \n",
    "    in the given column, ensuring the original distribution is maintained.\n",
    "    ----------\n",
    "    df : _type_\n",
    "        The input DataFrame containing data.\n",
    "    column_name : _type_\n",
    "        The name of column to use for stratified sampling.\n",
    "    sample_fraction : _type_\n",
    "        The fraction of data to sample from each category. (between 0 and 1)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A proportionately stratified sample of the input DataFrame.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If the sample_fraction is not between 0 and 1.\n",
    "    \"\"\" \n",
    "\n",
    "    if not (0<sample_fraction<=1):\n",
    "        raise ValueError(\"sample_fraction must be between 0 and 1\")\n",
    "    \n",
    "    #group by creates sub-dataframes for each unique value in the column\n",
    "    #apply allows us to apply a function to each of these sub-dataframes\n",
    "    #lambda applies sample to each sub-dataframe\n",
    "    \n",
    "    return df.groupby(column_name, group_keys=False).apply(lambda x: x.sample(frac=sample_fraction,random_state=42))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_dos_df=do_random_sampling(only_dos_df, 40000)\n",
    "sampled_fuzzy_df=do_random_sampling(only_fuzzy_df, 40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naz\\AppData\\Local\\Temp\\ipykernel_10420\\2371874293.py:34: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(column_name, group_keys=False).apply(lambda x: x.sample(frac=sample_fraction,random_state=42))\n",
      "C:\\Users\\Naz\\AppData\\Local\\Temp\\ipykernel_10420\\2371874293.py:34: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(column_name, group_keys=False).apply(lambda x: x.sample(frac=sample_fraction,random_state=42))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19778, 12)\n",
      "(9235, 12)\n",
      "(10041, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naz\\AppData\\Local\\Temp\\ipykernel_10420\\2371874293.py:34: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(column_name, group_keys=False).apply(lambda x: x.sample(frac=sample_fraction,random_state=42))\n"
     ]
    }
   ],
   "source": [
    "sampled_attack_free_df=do_proportionate_stratified_sampling(attack_free_df,\"dlc\",0.02)\n",
    "sampled_attack_free_inside_dos_df=do_proportionate_stratified_sampling(attack_free_inside_dos_df,\"dlc\",0.003)\n",
    "sampled_attack_free_inside_fuzzy_df=do_proportionate_stratified_sampling(attack_free_inside_fuzzy_df,\"dlc\",0.003)\n",
    "\n",
    "print(sampled_attack_free_df.shape)\n",
    "print(sampled_attack_free_inside_dos_df.shape)\n",
    "print(sampled_attack_free_inside_fuzzy_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_df_by_column(df,column_name):\n",
    "    \"\"\"\n",
    "\n",
    "    Sort the given DataFrame by the values in the specified column.\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The input DataFrame to sort.\n",
    "    column_name : str\n",
    "        The name of the column to use for sorting.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The input DataFrame sorted by the values in the specified column.\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If the column name is not found in the DataFrame.\n",
    "    \"\"\"\n",
    "    validate_column_in_dataframe(df,column_name)\n",
    "    return df.sort_values(by=column_name,ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_multiple_dfs_by_column(dfs,column_name):\n",
    "    \"\"\"\n",
    "    Sort multiple DataFrames by the values in the specified column.\n",
    "    ----------      \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dfs : list\n",
    "        List of DataFrames to sort.\n",
    "    column_name : str\n",
    "        The name of the column to use for sorting.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        List of DataFrames sorted by the values in the specified column.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If the column name is not found in any of the DataFrames.\n",
    "    \"\"\"\n",
    "    sorted_dfs=[]\n",
    "    for df in dfs:\n",
    "        validate_column_in_dataframe(df,column_name)\n",
    "        sorted_dfs.append(df.sort_values(by=column_name,ascending=True))\n",
    "    return sorted_dfs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list=[sampled_dos_df,sampled_fuzzy_df,sampled_attack_free_df,sampled_attack_free_inside_dos_df,sampled_attack_free_inside_fuzzy_df]\n",
    "column_name=\"timestamp\"\n",
    "sorted_dfs= sort_multiple_dfs_by_column(df_list,column_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dos_df,sorted_fuzzy_df,sorted_attack_free_df,sorted_attack_free_inside_dos_df,sorted_attack_free_inside_fuzzy_df=sorted_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_column_timestamp_to_datetime(df,column_name,new_column_name):\n",
    "    #ten digit timestamp suggessts seconds since epoch\n",
    "    \"\"\"\n",
    "    Convert a Unix timestamp to a datetime object and add it as a new column to the DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The input DataFrame containing the timestamp column.\n",
    "    column_name : str\n",
    "        The name of the column containing the Unix timestamp.\n",
    "    new_column_name : str\n",
    "        The name of the new column to add to the DataFrame.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A DataFrame with the new column added.\n",
    "    \"\"\"\n",
    " \n",
    "    validate_column_in_dataframe(df,column_name)\n",
    "    \n",
    "    df[new_column_name]=pd.to_datetime(df[column_name],unit='s')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_multiple_dfs_timestamp_to_datetime(dfs,column_name,new_column_name):\n",
    "    \"\"\"\n",
    "    Convert a Unix timestamp to a datetime object and add it as a new column to each DataFrame in the list.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dfs : list\n",
    "        List of DataFrames containing the timestamp column.\n",
    "    column_name : str\n",
    "        The name of the column containing the Unix timestamp.\n",
    "    new_column_name : str\n",
    "        The name of the new column to add to the DataFrame.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        List of DataFrames with the new column added.\n",
    "    \"\"\"\n",
    "    converted_dfs=[]\n",
    "    for df in dfs:\n",
    "        converted_dfs.append(convert_column_timestamp_to_datetime(df,column_name,new_column_name))\n",
    "    return converted_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>can_id</th>\n",
       "      <th>dlc</th>\n",
       "      <th>byte_0</th>\n",
       "      <th>byte_1</th>\n",
       "      <th>byte_2</th>\n",
       "      <th>byte_3</th>\n",
       "      <th>byte_4</th>\n",
       "      <th>byte_5</th>\n",
       "      <th>byte_6</th>\n",
       "      <th>byte_7</th>\n",
       "      <th>updated_flag</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>1.478198e+09</td>\n",
       "      <td>0000</td>\n",
       "      <td>8</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>T</td>\n",
       "      <td>2016-11-03 18:39:37.186119080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>1.478198e+09</td>\n",
       "      <td>0000</td>\n",
       "      <td>8</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>T</td>\n",
       "      <td>2016-11-03 18:39:37.188112974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>1.478198e+09</td>\n",
       "      <td>0000</td>\n",
       "      <td>8</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>T</td>\n",
       "      <td>2016-11-03 18:39:37.195993900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>1.478198e+09</td>\n",
       "      <td>0000</td>\n",
       "      <td>8</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>T</td>\n",
       "      <td>2016-11-03 18:39:37.199111938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>1.478198e+09</td>\n",
       "      <td>0000</td>\n",
       "      <td>8</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>T</td>\n",
       "      <td>2016-11-03 18:39:37.219604969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675494</th>\n",
       "      <td>1.478201e+09</td>\n",
       "      <td>0000</td>\n",
       "      <td>8</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>T</td>\n",
       "      <td>2016-11-03 19:17:30.705996037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675620</th>\n",
       "      <td>1.478201e+09</td>\n",
       "      <td>0000</td>\n",
       "      <td>8</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>T</td>\n",
       "      <td>2016-11-03 19:17:31.302994013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675627</th>\n",
       "      <td>1.478201e+09</td>\n",
       "      <td>0000</td>\n",
       "      <td>8</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>T</td>\n",
       "      <td>2016-11-03 19:17:31.304994106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675650</th>\n",
       "      <td>1.478201e+09</td>\n",
       "      <td>0000</td>\n",
       "      <td>8</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>T</td>\n",
       "      <td>2016-11-03 19:17:31.392564058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675657</th>\n",
       "      <td>1.478201e+09</td>\n",
       "      <td>0000</td>\n",
       "      <td>8</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>T</td>\n",
       "      <td>2016-11-03 19:17:31.400147915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp can_id  dlc byte_0 byte_1 byte_2 byte_3 byte_4 byte_5  \\\n",
       "1479     1.478198e+09   0000    8     00     00     00     00     00     00   \n",
       "1487     1.478198e+09   0000    8     00     00     00     00     00     00   \n",
       "1517     1.478198e+09   0000    8     00     00     00     00     00     00   \n",
       "1529     1.478198e+09   0000    8     00     00     00     00     00     00   \n",
       "1569     1.478198e+09   0000    8     00     00     00     00     00     00   \n",
       "...               ...    ...  ...    ...    ...    ...    ...    ...    ...   \n",
       "2675494  1.478201e+09   0000    8     00     00     00     00     00     00   \n",
       "2675620  1.478201e+09   0000    8     00     00     00     00     00     00   \n",
       "2675627  1.478201e+09   0000    8     00     00     00     00     00     00   \n",
       "2675650  1.478201e+09   0000    8     00     00     00     00     00     00   \n",
       "2675657  1.478201e+09   0000    8     00     00     00     00     00     00   \n",
       "\n",
       "        byte_6 byte_7 updated_flag                      datetime  \n",
       "1479        00     00            T 2016-11-03 18:39:37.186119080  \n",
       "1487        00     00            T 2016-11-03 18:39:37.188112974  \n",
       "1517        00     00            T 2016-11-03 18:39:37.195993900  \n",
       "1529        00     00            T 2016-11-03 18:39:37.199111938  \n",
       "1569        00     00            T 2016-11-03 18:39:37.219604969  \n",
       "...        ...    ...          ...                           ...  \n",
       "2675494     00     00            T 2016-11-03 19:17:30.705996037  \n",
       "2675620     00     00            T 2016-11-03 19:17:31.302994013  \n",
       "2675627     00     00            T 2016-11-03 19:17:31.304994106  \n",
       "2675650     00     00            T 2016-11-03 19:17:31.392564058  \n",
       "2675657     00     00            T 2016-11-03 19:17:31.400147915  \n",
       "\n",
       "[40000 rows x 13 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_column_timestamp_to_datetime(sorted_dos_df,\"timestamp\",\"datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naz-ids-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
